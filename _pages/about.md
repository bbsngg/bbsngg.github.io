---
permalink: /
title: "Dingjie Song"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Welcome! I am a Ph.D. student in the Department of Computer Science and Engineering at [Lehigh University](https://www.lehigh.edu/), advised by Prof. [Lichao Sun](https://lichao-sun.github.io/). Previously, I was a research assistant with the [CUHK-Shenzhen NLP group](https://freedomintelligence.github.io/), mentored by Dr. [Benyou Wang](https://wabyking.github.io/old.html). I obtained my M.E. from the [Software Institute](https://software.nju.edu.cn/) and [Natural Language Processing Group](http://nlp.nju.edu.cn/homepage/) at Nanjing University, under the guidance of Dr. [Xinyu Dai](https://ai.nju.edu.cn/daixinyu/index.htm) and Dr. [Jidong Ge](https://gjdnju.github.io/). Before that, I completed my B.E. at the [Software Institute](https://software.nju.edu.cn/) of Nanjing University.

<!-- Welcome! I am a research assistant affiliated with the [CUHK-Shenzhen NLP group](https://freedomintelligence.github.io/), under the guidance of Dr. [Benyou Wang](https://wabyking.github.io/old.html). I obtained my M.E. from the [Software Institute](https://software.nju.edu.cn/ "NJU SE") and the [Natural Language Processing Group](http://nlp.nju.edu.cn/homepage/ "NJU NLP") at Nanjing University, advised by Dr. [Xinyu Dai](https://ai.nju.edu.cn/daixinyu/index.htm) and Dr. [Jidong Ge](https://gjdnju.github.io/). Prior to this, I completed my B.E. at the [Software Institute](https://software.nju.edu.cn/ "NJU SE") of Nanjing University. -->

<!-- <span style="color:blue">**I am actively seeking Fall 2024 PhD and internship positions in ML/LLM/VLMs. Appreciate any interesting opportunities! :)**</span> -->

Email: [dingjiesong.cs@gmail.com](mailto:dingjiesong.cs@gmail.com)


[Google Scholar](https://scholar.google.com/citations?user=YLQ8DCsAAAAJ) / [CV](http://bbsngg.github.io/files/DingjieSong_Academic_CV_en.pdf)


Links: [Research Overview](#research-overview) / [Updates](#updates) / [Awards](#awards) / [Papers](#papers)


## Research Overview

My research interests are in Natural Language Processing, especially **intelligent interactive systems** 🤖 and **Domain-specific LLMs** 👨🏻‍⚕️ and the following directions:
* **Multimodal LLM** [\[COLM 2024\]](https://milebench.github.io/), [\[COLING 2025\]](https://github.com/FreedomIntelligence/TRIM), [\[NAACL 2025\]](https://arxiv.org/pdf/2311.13951), [\[ACL 2025\]](https://github.com/FreedomIntelligence/Med-MAT), [\[EMNLP Findings 2025,ICML 2025 DIG-BUG Workshop Oral\]](https://github.com/MLLM-Data-Contamination/MM-Detect), [\[EMNLP Findings 2025\]](https://github.com/FreedomIntelligence/LongLLaVA)
* **Medical LLM:** [\[NAACL 2024\]](https://arxiv.org/abs/2308.08833), [\[COLM 2024\]](https://arxiv.org/abs/2311.09774), [\[MICCAI 2025\]](https://arxiv.org/abs/2507.03698)
* **Multilingual LLM:** [\[NAACL 2024\]](https://arxiv.org/abs/2309.12053)
* **Task-oriented dialogue systems:** [\[NLPCC 2023 Oral\]](https://link.springer.com/chapter/10.1007/978-3-031-44693-1_3), [\[JCST 2023\]](https://link.springer.com/article/10.1007/s11390-022-2029-5)

## Updates

**Aug 2025**: 🎉🎉 [MM-Detect](https://github.com/MLLM-Data-Contamination/MM-Detect) and [LongLLaVA](https://github.com/FreedomIntelligence/LongLLaVA) were accepted to [EMNLP Findings'25](https://2025.emnlp.org/)!

**July 2025**: 🎉🎉 [SAMed-2](https://github.com/ZhilingYan/Medical-SAM-Bench) was accepted to [MICCAI'25](https://www.miccai.org/)!

**June 2025**: 🎉🎉 [MM-Detect](https://github.com/MLLM-Data-Contamination/MM-Detect) was accepted to [ICML'25 DIG-BUG Workshop](https://dig-bugs.github.io/)!

**May 2025**: 🎉🎉 [Med-MAT](https://github.com/FreedomIntelligence/Med-MAT) was accepted to [ACL'25](https://2025.aclweb.org/) main conference!

**Jan 2025**: 🎉🎉 [MLLM-Bench](https://arxiv.org/pdf/2311.13951) was accepted to [NAACL'25](https://2025.naacl.org/) main conference!

<details>

  <summary>Before 2025</summary>

  <p><strong>Dec 2024</strong>: 🎉🎉 <a href="https://arxiv.org/pdf/2409.10994">TRIM</a> was accepted to <a href="https://coling2025.org/">COLING'25</a> main conference!</p>

  <p><strong>Nov 2024</strong>: <strong>MM-Detect</strong> 🕵️ released! MM-Detect is the first <strong>Data Contamination Detection Framework</strong> for MLLMs!  More information can be found in <a href="https://arxiv.org/pdf/2411.03823">📃 paper</a> and the <a href="https://github.com/MLLM-Data-Contamination/MM-Detect">GitHub</a>.</p>

  <p><strong>Sep 2024</strong>: <strong>TRIM</strong> ✂️ released! TRIM is a simple yet effective <strong>Image Token Reduction Method</strong> for efficient MLLMs!  More information can be found in <a href="https://arxiv.org/pdf/2409.10994">📃 paper</a>, <a href="https://huggingface.co/FreedomIntelligence/llava-v1.5-7b-TRIM">🤗 HuggingFace</a> and the <a href="https://github.com/FreedomIntelligence/TRIM">GitHub</a>.</p>

  <p><strong>Sep 2024</strong>: <strong>LongLLaVA</strong> 🐍🦙 released! LongLLaVA is the first MLLM with <strong>hybrid architecture</strong> that can handle up to <strong>1000 images</strong>!  More information can be found in <a href="https://arxiv.org/pdf/2409.02889">📃 paper</a>, <a href="https://huggingface.co/FreedomIntelligence/LongLLaVA">🤗 HuggingFace</a> and the <a href="https://github.com/FreedomIntelligence/LongLLaVA">GitHub</a>. 🥈#2 Paper of the day on <a href="https://huggingface.co/papers/2409.02889">Huggingface Daily Paper</a>.</p>

  <p><strong>July 2024</strong>: 🎉🎉 Two papers <a href="https://milebench.github.io/">MileBench</a> and <a href="https://www.huatuogpt.cn/#/">HuatuoGPT2</a> were accepted to <a href="https://colmweb.org/">COLM'24</a> main conference!</p>

  <p><strong>April 2024</strong>: <strong>MileBench</strong> 🛣️ released! MileBench is a pioneering benchmark designed to rigorously test the <strong>MultImodal Long-contExt capabilities of MLLMs</strong>.  More information can be found on the <a href="https://milebench.github.io/">🌐 website</a>, <a href="https://arxiv.org/pdf/2404.18532">📃 paper</a>, <a href="https://huggingface.co/datasets/FreedomIntelligence/MileBench">🤗 HuggingFace</a> and the <a href="https://github.com/MileBench/MileBench">GitHub</a>.</p>

  <p><strong>March 2024</strong>: 🎉🎉 Two papers <a href="https://cmedbenchmark.llmzoo.com/#home">CMB</a> and <a href="https://arxiv.org/abs/2309.12053">AceGPT</a> were accepted to <a href="https://2024.naacl.org/">NAACL'24</a> main conference!</p>

  <summary>Before 2024</summary>

  <p><strong>Nov 2023</strong>: HuatuoGPT2 released! Try it out on the <a href="https://www.huatuogpt.cn/#/">🌐 demo</a>! HuatuoGPT2 employs an innovative domain adaptation method to significantly boost its medical knowledge and dialogue proficiency and showcases SOTA performance in several medical benchmarks, especially <strong>surpassing GPT-4 in expert evaluations and the fresh medical licensing exams</strong>. More info can be found in <a href="https://arxiv.org/abs/2311.09774">📃 paper</a> and <a href="https://huggingface.co/FreedomIntelligence/HuatuoGPT2-34B">🤗 HuggingFace</a>.</p>

  <p><strong>Sep 2023</strong>: We publish AceGPT that achieved <strong>top performance</strong> among open-source Arabic language models in benchmark tests. More info can be found in <a href="https://arxiv.org/abs/2309.12053">📃 paper</a> and <a href="https://huggingface.co/FreedomIntelligence/AceGPT-13B-chat">🤗 HuggingFace</a>.</p>

  <p><strong>Aug 2023</strong>: <a href="https://arxiv.org/abs/2308.08833">Checkout our 📃 new paper</a> that focuses on benchmarking prevalent Medical LLMs for their medical knowledge and clinical diagnostic capabilities. More information can be found on the <a href="https://cmedbenchmark.llmzoo.com/#home">🌐 website</a> and the <a href="https://huggingface.co/datasets/FreedomIntelligence/CMB">🤗 HuggingFace</a>.</p>

  <p><strong>Jul 2023</strong>: Start the journey in CUHK-sz as a research assistant under the guidance of <a href="https://scholar.google.com/citations?user=Jk4vJU8AAAAJ">Benyou Wang</a>.</p>

  <p><strong>Jun 2023</strong>: I defended my master's degree and got my master's degree in software engineering. Thanks to all those who have supported me.</p>

  <p><strong>Aug 2022 - Apr 2023</strong>: Finished my internship with <a href="https://scholar.google.com/citations?user=ozXuhOUAAAAJ">Jiaxing Zhang</a> on LLM SFT.</p>

</details>


## Papers
[Google Scholar](https://scholar.google.com/citations?user=YLQ8DCsAAAAJ)

### Preprints

* [Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents](https://arxiv.org/abs/2505.23450)
<br>
Zhejian Yang, Yongchao Chen, Xueyang Zhou, Jiangyue Yan, **Dingjie Song**, Yinuo Liu, Yuting Li, Yu Zhang, Pan Zhou, Hechang Chen, Lichao Sun
<br>
*arXiv, Under Review*, [project page](https://agentic-robot.github.io/)
<br>

* [Aligning Multimodal LLM with Human Preference: A Survey](https://arxiv.org/abs/2503.14504)
<br>
Tao Yu, Yi-Fan Zhang, Chaoyou Fu, Junkang Wu, Jinda Lu, Kun Wang, Xingyu Lu, Yunhang Shen, Guibin Zhang, **Dingjie Song**, Yibo Yan, Tianlong Xu, Qingsong Wen, Zhang Zhang, Yan Huang, Liang Wang, Tieniu Tan
<br>
*arXiv, Under Review*, [project page](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Alignment)
<br>

* [A Survey on Post-training of Large Language Models](https://arxiv.org/abs/2503.06072)
<br>
Guiyao Tie, Zeli Zhao, **Dingjie Song**, Fuyang Wei, Rong Zhou, Yurou Dai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng Xie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen, Yu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, Jianfeng Gao
<br>
*arXiv, Under Review*
<br>

* [From Correctness to Comprehension: AI Agents for Personalized Error Diagnosis in Education](https://arxiv.org/abs/2502.13789)
<br>
Yi-Fan Zhang, Hang Li, **Dingjie Song**, Lichao Sun, Tianlong Xu, Qingsong Wen
<br>
*arXiv, Under Review*
<br>

* [BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement](https://arxiv.org/pdf/2412.14203)
<br>
Yuhao Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, **Dingjie Song**, Bo Li, Yan Hu, Benyou Wang
<br>
*arxiv, Under Review*, [project page](https://github.com/FreedomIntelligence/BlenderLLM)
<br>

### 2025

* [LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture](https://arxiv.org/pdf/2409.02889)
<br>
Xidong Wang\*, **Dingjie Song\***, Shunian Chen, Chen Zhang, Benyou Wang
<br>
***EMNLP Findings 2025***, [project page](https://github.com/FreedomIntelligence/LongLLaVA/), [code and data](https://huggingface.co/FreedomIntelligence/LongLLaVA)
<br>


* [Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination](https://arxiv.org/pdf/2411.03823)
<br>
**Dingjie Song\***, Sicheng Lai\*, Mingxuan Wang, Shunian Chen, Lichao Sun, Benyou Wang
<br>
***EMNLP Findings 2025, ICML 2025 DIG-BUG Workshop <span style="color:#A52A2A;">Oral</span>***, [project page](https://github.com/MLLM-Data-Contamination/MM-Detect)
<br>


* [SAMed-2: Selective Memory Enhanced Medical Segment Anything Model](https://arxiv.org/abs/2507.03698)
<br>
Zhiling Yan, Sifan Song, **Dingjie Song**, Yiwei Li, Rong Zhou, Weixiang Sun, Zhennong Chen, Sekeun Kim, Hui Ren, Tianming Liu, Quanzheng Li, Xiang Li, Lifang He, Lichao Sun
<br>
***MICCAI 2025***, [code and data](https://github.com/ZhilingYan/Medical-SAM-Bench)
<br>

* [On the Compositional Generalization of Multimodal LLMs for Medical Imaging](https://arxiv.org/pdf/2412.20070)
<br>
Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, **Dingjie Song**, Yize Chen, Zixu Zhang, Benyou Wang
<br>
***ACL 2025***, [project page](https://github.com/FreedomIntelligence/Med-MAT)
<br>

* [MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria](https://arxiv.org/pdf/2311.13951)
<br>
Wentao Ge\*, Shunian Chen\*, Guiming Hardy Chen\*, Junying Chen, Zhihong Chen, Nuo Chen, Wenya Xie, Shuo Yan, Chenghao Zhu, Ziyue Lin, **Dingjie Song**, Xidong Wang, Anningzhe Gao, Zhang Zhiyi, Jianquan Li, Xiang Wan, Benyou Wang
<br>
***NAACL 2025***, [project page](https://mllm-bench.llmzoo.com/)
<br>

* [Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs](https://arxiv.org/pdf/2409.10994)
<br>
**Dingjie Song**, Wenjun Wang, Shunian Chen, Xidong Wang, Michael Guan, Benyou Wang
<br>
***COLING 2025***, [code and model](https://github.com/FreedomIntelligence/TRIM)
<br>

### 2024

* [MileBench: Benchmarking MLLMs in Long Context](https://arxiv.org/pdf/2404.18532)
<br>
**Dingjie Song**, Shunian Chen, Guiming Hardy Chen, Fei Yu, Xiang Wan, Benyou Wang
<br>
***COLM 2024***, [project page](https://milebench.github.io/), [code and data](https://github.com/MileBench/MileBench)
<br>

* [HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs](https://arxiv.org/abs/2311.09774)
<br>
Junying Chen, Xidong Wang, Anningzhe Gao, Feng Jiang, Shunian Chen, Hongbo Zhang, **Dingjie Song**, Wenya Xie, Chuyi Kong, Jianquan Li, Xiang Wan, Haizhou Li, Benyou Wang
<br>
***COLM 2024***, [project page](https://www.huatuogpt.cn/), [code and data](https://github.com/FreedomIntelligence/HuatuoGPT-II)
<br>

* [AceGPT, Localizing Large Language Models in Arabic](https://arxiv.org/abs/2309.12053)
<br>
Huang Huang\*, Fei Yu\*, Jianqing Zhu\*, Xuening Sun, Hao Cheng, **Dingjie Song**, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Juncai He, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu
<br>
***NAACL 2024***, [code and data](https://github.com/FreedomIntelligence/AceGPT)
<br>

* [CMB: A Comprehensive Medical Benchmark in Chinese](https://arxiv.org/abs/2308.08833)
<br>
Xidong Wang\*, Guiming Hardy Chen\*, **Dingjie Song\***, Zhiyi Zhang\*, Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li
<br>
***NAACL 2024***, [project page](https://cmedbenchmark.llmzoo.com/#home), [code and data](https://github.com/FreedomIntelligence/CMB)
<br>


### 2023

* [Episode-based Prompt Learning for Any-shot Intent Detection](https://link.springer.com/chapter/10.1007/978-3-031-44693-1_3)
<br>
Pengfei Sun\*, **Dingjie Song\***, Yawen Ouyang, Zhen Wu, Xinyu Dai
<br>
***NLPCC 2023 <span style="color:#A52A2A;">Oral</span>***
<br>


### 2022

* [Self-Supervised Task Augmentation for Few-Shot Intent Detection](https://link.springer.com/article/10.1007/s11390-022-2029-5)
<br>
Pengfei Sun, Yawen Ouyang, **Dingjie Song**, Xinyu Dai
<br>
***JCST 2022***,
[code and data](https://github.com/bbsngg/STAM)
<br>

---

## Awards

* Outstanding Graduate Student, Nanjing University, 2022
* Yingcai Scholarship, Nanjing University, 2022
* Renmin Scholarship (People’s Scholarship), Nanjing University, 2018-2021
* Third Runner's Up in 15th Citi Cup Financial Innovation Application Competition, Citigroup, 2019
* Second Runner's Up in 2019 "Chain to Future" University Blockchain Technology Application Competition, CCF, 2019
* Outstanding Student Leader of the Communist Youth League, Nanjing University, 2018-2019

## Services

* *Conference reviewer:* EMNLP, ACL Rolling Review

<div align="center">
    <a href='https://mapmyvisitors.com/web/1bvss'  title='Visit tracker'>
        <img src='https://mapmyvisitors.com/map.png?cl=ffffff&w=300&t=tt&d=pJ1pgUuPoKJii9Zaz72RjAS-htRZQIO-WrxhoD-fe6Y&co=2d78ad&ct=ffffff'/>
    </a>
</div>
