{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\texcerpt\tcitation\turl_slug\tpaper_url\n",
      "2023-11-16\tHuatuoGPT-II, One-stage Training for Medical Adaption of LLMs\tarXiv\tJunying Chen, Xidong Wang, Anningzhe Gao, Feng Jiang, Shunian Chen, Hongbo Zhang, Dingjie Song, Wenya Xie, Chuyi Kong, Jianquan Li, Xiang Wan, Haizhou Li, Benyou Wang\tHuatuoGPT-II, One-stage Training for Medical Adaption of LLMs\thttps://arxiv.org/abs/2311.09774\n",
      "2023-09-21\tAceGPT, Localizing Large Language Models in Arabic\tarXiv\tHuang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Juncai He, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu\tAceGPT, Localizing Large Language Models in Arabic\thttps://arxiv.org/abs/2309.12053\n",
      "2023-08-17\tCMB: A Comprehensive Medical Benchmark in Chinese\tarXiv\tXidong Wang, Guiming Hardy Chen, Dingjie Song (equal contribution), Zhiyi Zhang (equal contribution), Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li\tCMB: A Comprehensive Medical Benchmark in Chinese\thttps://arxiv.org/abs/2308.08833\n",
      "2023-10-08\tEpisode-based Prompt Learning for Any-shot Intent Detection\tNLPCC 2023 Oral\tPengfei Sun, Dingjie Song (equal contribution), Yawen Ouyang, Zhen Wu, Xinyu Dai\tEpisode-based Prompt Learning for Any-shot Intent Detection\thttps://link.springer.com/chapter/10.1007/978-3-031-44693-1_3\n",
      "2022-05-31\tSelf-Supervised Task Augmentation for Few-Shot Intent Detection\tJCST 2022\tPengfei Sun, Yawen Ouyang, Dingjie Song, Xinyu Dai\tSelf-Supervised Task Augmentation for Few-Shot Intent Detection\thttps://link.springer.com/article/10.1007/s11390-022-2029-5\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>citation</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>HuatuoGPT-II, One-stage Training for Medical A...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>Junying Chen, Xidong Wang, Anningzhe Gao, Feng...</td>\n",
       "      <td>HuatuoGPT-II, One-stage Training for Medical A...</td>\n",
       "      <td>https://arxiv.org/abs/2311.09774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>AceGPT, Localizing Large Language Models in Ar...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun...</td>\n",
       "      <td>AceGPT, Localizing Large Language Models in Ar...</td>\n",
       "      <td>https://arxiv.org/abs/2309.12053</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>CMB: A Comprehensive Medical Benchmark in Chinese</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>Xidong Wang, Guiming Hardy Chen, Dingjie Song ...</td>\n",
       "      <td>CMB: A Comprehensive Medical Benchmark in Chinese</td>\n",
       "      <td>https://arxiv.org/abs/2308.08833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>Episode-based Prompt Learning for Any-shot Int...</td>\n",
       "      <td>NLPCC 2023 Oral</td>\n",
       "      <td>Pengfei Sun, Dingjie Song (equal contribution)...</td>\n",
       "      <td>Episode-based Prompt Learning for Any-shot Int...</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>Self-Supervised Task Augmentation for Few-Shot...</td>\n",
       "      <td>JCST 2022</td>\n",
       "      <td>Pengfei Sun, Yawen Ouyang, Dingjie Song, Xinyu...</td>\n",
       "      <td>Self-Supervised Task Augmentation for Few-Shot...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s113...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                              title  \\\n",
       "0  2023-11-16  HuatuoGPT-II, One-stage Training for Medical A...   \n",
       "1  2023-09-21  AceGPT, Localizing Large Language Models in Ar...   \n",
       "2  2023-08-17  CMB: A Comprehensive Medical Benchmark in Chinese   \n",
       "3  2023-10-08  Episode-based Prompt Learning for Any-shot Int...   \n",
       "4  2022-05-31  Self-Supervised Task Augmentation for Few-Shot...   \n",
       "\n",
       "             venue                                            excerpt  \\\n",
       "0            arXiv  Junying Chen, Xidong Wang, Anningzhe Gao, Feng...   \n",
       "1            arXiv  Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun...   \n",
       "2            arXiv  Xidong Wang, Guiming Hardy Chen, Dingjie Song ...   \n",
       "3  NLPCC 2023 Oral  Pengfei Sun, Dingjie Song (equal contribution)...   \n",
       "4        JCST 2022  Pengfei Sun, Yawen Ouyang, Dingjie Song, Xinyu...   \n",
       "\n",
       "                                            citation  \\\n",
       "0  HuatuoGPT-II, One-stage Training for Medical A...   \n",
       "1  AceGPT, Localizing Large Language Models in Ar...   \n",
       "2  CMB: A Comprehensive Medical Benchmark in Chinese   \n",
       "3  Episode-based Prompt Learning for Any-shot Int...   \n",
       "4  Self-Supervised Task Augmentation for Few-Shot...   \n",
       "\n",
       "                                            url_slug  paper_url  \n",
       "0                   https://arxiv.org/abs/2311.09774        NaN  \n",
       "1                   https://arxiv.org/abs/2309.12053        NaN  \n",
       "2                   https://arxiv.org/abs/2308.08833        NaN  \n",
       "3  https://link.springer.com/chapter/10.1007/978-...        NaN  \n",
       "4  https://link.springer.com/article/10.1007/s113...        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "\n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "\n",
    "    ## YAML variables\n",
    "\n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "\n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "\n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "\n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "\n",
    "    md += \"\\ndate: \" + str(item.pub_date)\n",
    "\n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "\n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "\n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "\n",
    "    md += \"\\n---\"\n",
    "\n",
    "    ## Markdown description for individual page\n",
    "\n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "\n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\"\n",
    "\n",
    "    md += \"\\nRecommended citation: \" + item.citation\n",
    "\n",
    "    md_filename = os.path.basename(md_filename)\n",
    "\n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-10-01-paper-title-number-2.md\n",
      "2015-10-01-paper-title-number-3.md\n",
      "2023-08-17-cmb-comprehensive-medical-benchmark-chinese.md\n",
      "2308.08833.md\n",
      "2309.12053.md\n",
      "2311.09774.md\n",
      "978-3-031-44693-1_3.md\n",
      "s11390-022-2029-5.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"CMB: A Comprehensive Medical Benchmark in Chinese\"\n",
      "collection: publications\n",
      "permalink: /publication/2023-08-17-https://arxiv.org/abs/2308.08833\n",
      "excerpt: 'Xidong Wang, Guiming Hardy Chen, Dingjie Song (equal contribution), Zhiyi Zhang (equal contribution), Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li'\n",
      "date: 2023-08-17\n",
      "venue: 'arXiv'\n",
      "citation: 'CMB: A Comprehensive Medical Benchmark in Chinese'\n",
      "---\n",
      "Xidong Wang, Guiming Hardy Chen, Dingjie Song (equal contribution), Zhiyi Zhang (equal contribution), Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li\n",
      "\n",
      "Recommended citation: CMB: A Comprehensive Medical Benchmark in Chinese"
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2308.08833.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
